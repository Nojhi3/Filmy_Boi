# üé¨ Movie Character Chatbot (Django + Celery + Redis + ChromaDB)

## üìå Project Overview
This is a **REST API** built using **Django REST Framework (DRF)** that allows users to chat with movie characters. It uses:
- **ChromaDB** for semantic search (Retrieval-Augmented Generation - RAG).
- **Together AI Llama-3.1-8B** for AI-generated responses.
- **Redis (via Docker)** for caching and Celery task queue.
- **Celery** for background processing.
- **PostgreSQL (Optional)** for storing structured movie dialogues.

---

## üöÄ Features
‚úÖ **Retrieves real movie dialogues before AI generation**
‚úÖ **Uses vector embeddings for semantic search** (ChromaDB + BGE model)
‚úÖ **Caches responses in Redis for faster retrieval**
‚úÖ **Async processing with Celery to prevent API blocking**
‚úÖ **Rate limiting (5 requests/sec per user)**
‚úÖ **Load testing using Locust**

---

## üõ†Ô∏è Installation & Setup
### **1Ô∏è‚É£ Clone the Repository**
```bash
git clone https://github.com/your-username/movie-character-chatbot.git
cd movie-character-chatbot
```

### **2Ô∏è‚É£ Create Virtual Environment & Install Dependencies**
```bash
python -m venv venv
source venv/bin/activate   # On Windows use `venv\Scripts\activate`
pip install -r requirements.txt
```

### **3Ô∏è‚É£ Set Up Environment Variables (`.env` file)**
Create a `.env` file in the project root:
```ini
SECRET_KEY=your-django-secret-key
DEBUG=True
ALLOWED_HOSTS=127.0.0.1,localhost

# Database (PostgreSQL Optional)
DATABASE_URL=postgres://your_user:your_password@localhost:5432/movie_db

# Redis (For Celery & Caching)
REDIS_URL=redis://127.0.0.1:6379/0

# Together AI API Key (for Llama-3.1-8B)
TOGETHER_API_KEY=your-api-key
```

---

## üê≥ Running with Docker (Recommended)
### **1Ô∏è‚É£ Build & Run the Containers**
```bash
docker-compose up -d --build
```

### **2Ô∏è‚É£ Check Running Containers**
```bash
docker ps
```

### **3Ô∏è‚É£ Verify Redis is Running**
```bash
docker exec -it redis_cache redis-cli ping
```
‚úÖ Expected Output: `PONG`

---

## üì° API Endpoints
### **POST `/api/chat/`** (Chat with a Movie Character)
**Request:**
```json
{
  "character": "jules winnfield",
  "user_message": "Say what again!"
}
```

**Response:**
```json
{
  "response": "English, motherf***er! Do you speak it?!"
}
```

### **GET `/api/health/`** (Check API Health)
```bash
curl -X GET http://127.0.0.1:8000/api/health/
```

---

## üìä Load Testing with Locust
### **1Ô∏è‚É£ Install Locust**
```bash
pip install locust
```

### **2Ô∏è‚É£ Create `locustfile.py`**
```python
from locust import HttpUser, task, between

class ChatUser(HttpUser):
    wait_time = between(1, 2)
    
    @task
    def send_message(self):
        self.client.post("/api/chat/", json={
            "character": "jules winnfield", "user_message": "Say what again!"
        })
```

### **3Ô∏è‚É£ Run Locust**
```bash
locust -f locustfile.py
```
- Open **http://localhost:8089** to start the test.

---

## üîç Debugging & Troubleshooting
### **1Ô∏è‚É£ Check Docker Logs**
```bash
docker logs redis_cache
```

### **2Ô∏è‚É£ Check Celery Worker Logs**
```bash
celery -A chat worker --loglevel=info
```

### **3Ô∏è‚É£ Check Redis Connection**
```bash
docker exec -it redis_cache redis-cli ping
```
‚úÖ Expected Output: `PONG`

---

## üìú License
MIT License - Free to use and modify. ‚ù§Ô∏è

